tensor([[ 0.0535, -0.0568,  0.1068, -0.0040, -0.0220,  0.0301, -0.0879, -0.0589,
          0.0327, -0.0109],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [ 0.0495,  0.0061,  0.0522, -0.0384, -0.0209,  0.0002, -0.0580, -0.0662,
         -0.0359, -0.0147],
        [ 0.0645, -0.0997,  0.0776, -0.0486, -0.0898, -0.0020, -0.0491, -0.1070,
          0.0267,  0.0061],
        [-0.0073, -0.0322,  0.0615, -0.0540,  0.0127,  0.0342, -0.0429, -0.0489,
          0.0167, -0.0435],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [ 0.0515, -0.0698,  0.0304, -0.0440, -0.0198, -0.0420, -0.0968, -0.0521,
         -0.0045, -0.0016],
        [ 0.0480, -0.0432,  0.0696, -0.0619, -0.0093,  0.0106, -0.0704, -0.0777,
          0.0078, -0.0426],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [ 0.0531, -0.0809,  0.0575, -0.0474, -0.0457,  0.0501, -0.0752, -0.0842,
          0.0214, -0.0437],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [ 0.0422, -0.0910,  0.0451, -0.0272, -0.0439,  0.0249, -0.0519, -0.0700,
         -0.0085, -0.0048],
        [ 0.0364, -0.0470,  0.0381, -0.0494, -0.0192,  0.0022, -0.0605, -0.0963,
          0.0256, -0.0511],
        [ 0.0316, -0.0475,  0.0531, -0.0305,  0.0170, -0.0032, -0.0705, -0.0462,
          0.0305, -0.0040],
        [ 0.0514, -0.0554,  0.0466, -0.0745, -0.0243,  0.0489, -0.0725, -0.0733,
          0.0186, -0.0156],
        [ 0.0284, -0.0419,  0.0513, -0.0360, -0.0091,  0.0118, -0.0787, -0.0774,
          0.0239, -0.0426],
        [ 0.0484, -0.0745,  0.0666, -0.0447,  0.0149,  0.0172, -0.0286, -0.0672,
          0.0729, -0.0109],
        [ 0.0493, -0.0859,  0.1125, -0.0424, -0.0349,  0.0532, -0.0749, -0.0585,
          0.0146,  0.0042],
        [ 0.0824, -0.0681,  0.0666, -0.0763, -0.0449,  0.0235, -0.0606, -0.0957,
          0.0318, -0.0394],
        [ 0.0050, -0.0793,  0.0608, -0.0127, -0.0019,  0.0178, -0.0569, -0.0760,
          0.0381, -0.0363],
        [ 0.0500, -0.0696,  0.0491, -0.0337, -0.0624,  0.0137, -0.0496, -0.0966,
          0.0455, -0.0390],
        [ 0.0330, -0.0585,  0.0499, -0.0554, -0.0573,  0.0109, -0.0438, -0.0980,
          0.0432, -0.0344],
        [ 0.0595, -0.0623,  0.0789, -0.0568, -0.0079,  0.0594, -0.0825, -0.0295,
          0.0141,  0.0337],
        [ 0.0510, -0.0309,  0.1022, -0.0527, -0.0322,  0.0453, -0.0599, -0.0715,
          0.0276, -0.0326],
        [ 0.0590, -0.0796,  0.0888, -0.0242, -0.0494,  0.0879, -0.0697, -0.0608,
          0.0044, -0.0136],
        [ 0.0274, -0.0765,  0.0637, -0.0641, -0.0244, -0.0033, -0.0871, -0.0792,
          0.0649, -0.0137],
        [ 0.0474, -0.0967,  0.0784, -0.0608, -0.0457,  0.0402, -0.0401, -0.0730,
          0.0224, -0.0326],
        [ 0.0407, -0.0646,  0.0441, -0.0642, -0.0452,  0.0315, -0.0576, -0.0990,
          0.0308, -0.0319],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [ 0.0295, -0.0409,  0.0363, -0.0935, -0.0207,  0.0361, -0.0714, -0.0556,
          0.0034,  0.0039],
        [ 0.0772, -0.0569,  0.0894, -0.0082, -0.0154,  0.0496, -0.1308, -0.0811,
          0.0341, -0.0106],
        [ 0.0489, -0.0905,  0.0703, -0.0317, -0.0232,  0.0368, -0.0592, -0.0559,
          0.0243, -0.0216],
        [ 0.0422, -0.0283,  0.0338, -0.0365,  0.0318,  0.0107, -0.0942, -0.0540,
         -0.0128,  0.0111],
        [ 0.0336, -0.0715,  0.0500, -0.0570, -0.0370, -0.0055, -0.0643, -0.0763,
          0.0142,  0.0169],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [ 0.0359, -0.0647,  0.0567, -0.0258, -0.0664,  0.0451, -0.0620, -0.0725,
          0.0025, -0.0621],
        [ 0.0713, -0.0625,  0.0301, -0.0476, -0.0061,  0.0115, -0.0371, -0.0593,
          0.0802, -0.0240],
        [ 0.0584, -0.0548,  0.0747, -0.0491, -0.0029,  0.0192, -0.0694, -0.0405,
          0.0108,  0.0051],
        [ 0.0273, -0.0405,  0.0435, -0.0865, -0.0256,  0.0318, -0.0549, -0.0892,
         -0.0094, -0.0454],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [ 0.0493, -0.0645,  0.1174,  0.0018, -0.0202,  0.0369, -0.0848, -0.0375,
          0.0295,  0.0377],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [ 0.0291, -0.0532,  0.0798, -0.0348,  0.0053,  0.0260, -0.0469, -0.0347,
          0.0330, -0.0052],
        [ 0.0368, -0.0124,  0.0421, -0.0565, -0.0547,  0.0531, -0.0382, -0.0953,
         -0.0146, -0.0797],
        [ 0.0553, -0.0697,  0.0478, -0.0393, -0.0251,  0.0352, -0.0402, -0.1146,
          0.0461, -0.0695],
        [ 0.0325, -0.0730,  0.0650, -0.0217, -0.0226,  0.0492, -0.0399, -0.0558,
         -0.0052, -0.0109],
        [ 0.0665, -0.0671,  0.0686, -0.0425, -0.0498,  0.0210, -0.0665, -0.0727,
          0.0215,  0.0028],
        [ 0.0462, -0.0795,  0.0616, -0.1020, -0.0178,  0.0339, -0.0356, -0.0903,
          0.0652, -0.0269],
        [    nan,     nan,     nan,     nan,     nan,     nan,     nan,     nan,
             nan,     nan],
        [ 0.0516, -0.0542,  0.0893, -0.0088, -0.0133,  0.0512, -0.0511, -0.0524,
          0.0356,  0.0072],
        [ 0.0482, -0.0424,  0.0746, -0.0737, -0.0235,  0.0503, -0.0596, -0.0564,
          0.0252, -0.0340],
        [ 0.0231, -0.0383,  0.0574, -0.0639, -0.0301,  0.0518, -0.0304, -0.0717,
         -0.0108, -0.0148],
        [ 0.0548, -0.1111,  0.0762, -0.0489, -0.0268, -0.0018, -0.0640, -0.0818,
          0.0500, -0.0307],
        [ 0.0463, -0.0489,  0.0328, -0.0535, -0.0327,  0.0141, -0.0607, -0.0935,
          0.0222, -0.0686],
        [ 0.0713, -0.0798,  0.0488, -0.0574, -0.0340,  0.0305, -0.0499, -0.0516,
          0.0120, -0.0016],
        [ 0.0430, -0.0651,  0.0809, -0.0677, -0.0390,  0.0467, -0.0602, -0.0708,
          0.0135, -0.0258],
        [ 0.0362, -0.0592,  0.0404, -0.0517, -0.0355, -0.0018, -0.0509, -0.0898,
          0.0405, -0.0576],
        [ 0.0250, -0.0299,  0.0585, -0.0524, -0.0339,  0.0326, -0.0357, -0.0848,
         -0.0031, -0.0310],
        [ 0.0419, -0.0974,  0.0629, -0.0025, -0.0368,  0.0223, -0.0635, -0.0959,
          0.0693, -0.0337],
        [ 0.0426, -0.0838,  0.0788, -0.0752,  0.0003,  0.0344, -0.0568, -0.0806,
          0.0628, -0.0336],
        [ 0.0810, -0.0511,  0.0649, -0.0436, -0.0391,  0.0173, -0.0747, -0.0457,
          0.0334, -0.0136]], device='mps:0', grad_fn=<LinearBackward0>) tensor([7, 6, 7, 9, 9, 0, 8, 0, 2, 0, 2, 7, 8, 9, 1, 0, 8, 7, 0, 8, 2, 3, 8, 8,
        6, 6, 3, 1, 6, 0, 6, 0, 1, 6, 6, 3, 7, 6, 9, 2, 2, 0, 7, 9, 6, 9, 3, 9,
        9, 9, 3, 6, 0, 9, 0, 1, 9, 0, 7, 1, 7, 9, 2, 7], device='mps:0') tensor(nan, device='mps:0', grad_fn=<NllLossBackward0>)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]], device='mps:0',
       grad_fn=<LinearBackward0>) tensor([9, 0, 3, 3, 0, 8, 1, 6, 2, 6, 0, 6, 9, 3, 0, 7, 9, 9, 9, 6, 6, 9, 9, 6,
        9, 0, 2, 7, 9, 8, 0, 6, 9, 8, 0, 6, 6, 0, 2, 0, 9, 7, 0, 6, 0, 9, 2, 7,
        0, 3, 9, 6, 3, 2, 8, 0, 0, 3, 9, 8, 3, 0, 6, 6], device='mps:0') tensor(nan, device='mps:0', grad_fn=<NllLossBackward0>)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]], device='mps:0',
       grad_fn=<LinearBackward0>) tensor([6, 0, 7, 8, 9, 3, 3, 2, 1, 8, 0, 3, 8, 3, 2, 0, 3, 2, 9, 9, 9, 3, 8, 0,
        1, 8, 9, 1, 9, 0, 9, 3, 1, 1, 9, 8, 0, 0, 7, 8, 1, 9, 7, 2, 9, 3, 2, 0,
        0, 3, 0, 2, 2, 8, 2, 9, 0, 3, 7, 6, 7, 9, 7, 0], device='mps:0') tensor(nan, device='mps:0', grad_fn=<NllLossBackward0>)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]], device='mps:0',
       grad_fn=<LinearBackward0>) tensor([8, 0, 7, 7, 3, 8, 7, 3, 8, 1, 1, 9, 6, 1, 2, 1, 0, 6, 2, 0, 9, 0, 2, 0,
        2, 9, 0, 7, 7, 6, 0, 1, 3, 9, 3, 3, 2, 6, 0, 9, 3, 9, 7, 0, 6, 8, 2, 9,
        1, 2, 1, 1, 0, 9, 9, 9, 0, 6, 9, 0, 8, 9, 7, 0], device='mps:0') tensor(nan, device='mps:0', grad_fn=<NllLossBackward0>)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]], device='mps:0',
       grad_fn=<LinearBackward0>) tensor([8, 9, 0, 9, 8, 2, 3, 0, 2, 2, 6, 2, 2, 0, 9, 2, 1, 3, 1, 2, 8, 0, 8, 8,
        3, 7, 6, 8, 7, 2, 0, 8, 0, 3, 8, 2, 6, 0, 6, 0, 0, 3, 0, 9, 3, 7, 9, 9,
        0, 3, 6, 8, 0, 3, 0, 7, 9, 9, 7, 0, 3, 8, 7, 9], device='mps:0') tensor(nan, device='mps:0', grad_fn=<NllLossBackward0>)
tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]], device='mps:0',
       grad_fn=<LinearBackward0>) tensor([0, 3, 3, 7, 9, 3, 0, 9, 7, 8, 1, 9, 3, 0, 9, 0, 3, 7, 1, 1, 9, 6, 1, 3,
        9, 2, 9, 9, 7, 9, 9, 0, 0, 6, 9, 6, 0, 3, 6, 9, 9, 7, 9, 2, 9, 3, 0, 7,
